# -*- coding: utf-8 -*-
"""ECT_HW10_107403510

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KNYn7PB0-JdvbimIiISkmIKINEB4jfag

# 取得apk的permission當作特徵
1. 安裝Androguard
2. 把全部檔案解壓縮
3. 利用androgaurd取得permission(自訂get_permissions函數)
4. 將取得的permission跟對應的apk存成csv檔儲存(此csv檔非跑模型的資料集)
"""

pip install -U androguard[magic,GUI]

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign1.tar'

!unzip "DDD.zip"

permission_list = []
error_list = []
apkname_list = []

from androguard.core.bytecodes import apk, dvm
from androguard.core.analysis import analysis
def get_permissions(path, filename):
    str = "Permission:"
    try:
      app = apk.APK(path)
      permission = app.get_permissions()
      #print(type(permission))
      file = permission
      permission_list.append(permission)
      apkname_list.append(path.split("/")[-1])
      print(permission)
    except Exception as e:
      print(e)
      error_list.append(path.split("/")[-1])

import os
#用自訂函數取permssions
for root, dirs, files in os.walk("DDD", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

permission_list[350]

#將permissions和apk製成DataFrame
b1 = pd.DataFrame(permission_list).T

apknames = []
for root, dirs, files in os.walk("DDD", topdown=False):
    for name in files:
        apknames.append(name)

#DataFrame欄位名稱改成apk名稱
b1.columns = apknames

b1.to_csv("benign1_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/SMS.tar.gz'

import os
#用get_permissions取permissions
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("SMS", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

len(permission_list)

error_list

len(error_list)

import pandas as pd
#將取得的permission跟apk製成一個DataFrame(欄為apk, 列為permission)
sms = pd.DataFrame(permission_list).T
sms

#把DataFrame的欄位改成apk名稱
sms.columns = apkname_list
sms

#存成csv檔
sms.to_csv("sms_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Adware.tar.gz'

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Adware", topdown=False):
    for name in files:
        #print(os.path.join(root, name))
        path = os.path.join(root, name)
    #for name in dirs:
    #    print(os.path.join(root, name))
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
#將permissions和apk製成DataFrame(欄為apk, 列為permission)
Adware = pd.DataFrame(permission_list).T
Adware

#欄位名稱改成apk名稱
Adware.columns = apkname_list
Adware

#存成csv檔
Adware.to_csv("Adware_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign2.tar'

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("DDD", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
b2 = pd.DataFrame(permission_list).T
b2

b2.columns = apkname_list
b2

b2.to_csv("benign2_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign3.tar' --directory "./Benign3"

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Benign3", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

len(permission_list)

error_list

len(error_list)

import pandas as pd
b3 = pd.DataFrame(permission_list).T
b3

b3.columns = apkname_list
b3

b3.to_csv("benign3_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign4.tar' --directory "./Benign4"

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Benign4", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
b4 = pd.DataFrame(permission_list).T
b4

b4.columns = apkname_list
b4

b4.to_csv("benign4_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign5.tar' --directory "./Benign5"

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Benign5", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
b5 = pd.DataFrame(permission_list).T
b5

b5.columns = apkname_list
b5

b5.to_csv("benign5_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign6.tar' --directory "./Benign6"

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Benign6", topdown=False):
    for name in files:
        #print(os.path.join(root, name))
        path = os.path.join(root, name)
    #for name in dirs:
    #    print(os.path.join(root, name))
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
b6 = pd.DataFrame(permission_list).T
b6

b6.columns = apkname_list
b6

b6.to_csv("benign6_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign7_.tar' --directory "./Benign7"

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Benign7", topdown=False):
    for name in files:
        #print(os.path.join(root, name))
        path = os.path.join(root, name)
    #for name in dirs:
    #    print(os.path.join(root, name))
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
b7 = pd.DataFrame(permission_list).T
b7

b7.columns = apkname_list
b7

b7.to_csv("benign7_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign8.tar' --directory "./Benign8"

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Benign8", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
b8 = pd.DataFrame(permission_list).T
b8

b8.columns = apkname_list
b8

b8.to_csv("benign8_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign9.tar' --directory "./Benign9"

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Benign9", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
b9 = pd.DataFrame(permission_list).T
b9

b9.columns = apkname_list
b9

b9.to_csv("benign9_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Benign/Benign10.tar' --directory "./Benign10"

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Benign10", topdown=False):
    for name in files:
        
        path = os.path.join(root, name)
    
        get_permissions(path, "t")

len(permission_list)

error_list

import pandas as pd
b10 = pd.DataFrame(permission_list).T
b10

b10.columns = apkname_list
b10

b10.to_csv("benign10_permission.csv")

!tar -xvf './drive/MyDrive/ECT_HW10_dataset/Banking.tar.gz'

import os
permission_list = []
error_list = []
apkname_list = []
for root, dirs, files in os.walk("Banking", topdown=False):
    for name in files:
        #print(os.path.join(root, name))
        path = os.path.join(root, name)
    #for name in dirs:
    #    print(os.path.join(root, name))
        get_permissions(path, "t")

len(permission_list)

error_list

len(error_list)

import pandas as pd
#將取得的permission跟apk製成一個DataFrame(欄為apk, 列為permission)
Banking = pd.DataFrame(permission_list).T
Banking

#欄位名稱改成apk名稱
Banking.columns = apkname_list
Banking

Banking.to_csv("Banking_permission.csv")

"""# 前處理
1. 讀入前面存的13個csv檔，對每個欄位的值做處理，只留permission的字
2. 找出SMS,Adware,Banking malware排名前50的permission
3. 找出Benign的排名前50的permission
4. 用挑出的malware和Benign的permission，把全部的apk用成放入模型的dataframe資料集(apk_dataset.csv)
5. 資料切成train和test的data
"""

import pandas as pd
#sms
sms = pd.read_csv("sms_permission.csv")
sms

malware_total_permission = []

#刪除android.permission
import numpy as np

for column in sms.columns:
  l = []
  for v in sms[column]:
    #因為第一欄是索引且各欄位有NaN，所以先判斷是String的才要處理
    if isinstance(v, str):
      v = v.split(".")[-1] #只留最後一部分的字
      malware_total_permission.append(v)
    else:
      v = "non"
    #print(v)
    l.append(v)
  sms[column] = l
    #print(type(v))

sms_arr = np.array(sms)
unique, counts = np.unique(sms_arr, return_counts=True)
sms_permissionNum = pd.DataFrame(counts, index=unique, columns=["permission"])
sms_permissionNum.drop(['non'],inplace=True)
sms_permissionNum

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

plt.figure(figsize=(15,30))
x = [index for index in sms_permissionNum.index]
y = [int(value) for value in sms_permissionNum.values]
plt.barh(x,y)

#adware
adware = pd.read_csv("Adware_permission.csv")
adware

#刪除android.permission
import numpy as np

for column in adware.columns:
  l = []
  for v in adware[column]:
    #因為第一欄是索引且各欄位有NaN，所以先判斷是String的才要處理
    if isinstance(v, str):
      v = v.split(".")[-1] #只保留最後一部分的字
      malware_total_permission.append(v)
    else:
      v = "non"
    #print(v)
    l.append(v)
  adware[column] = l
    #print(type(v))

adware_arr = np.array(adware)
unique, counts = np.unique(adware_arr, return_counts=True)
adware_permissionNum = pd.DataFrame(counts, index=unique, columns=["permission"])
adware_permissionNum.drop(['non'],inplace=True)
adware_permissionNum

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

plt.figure(figsize=(15,35))
x = [index for index in adware_permissionNum.index]
y = [int(value) for value in adware_permissionNum.values]
plt.barh(x,y)

#banking
bank = pd.read_csv("Banking_permission.csv")
bank

#刪除android.permission
import numpy as np

for column in bank.columns:
  l = []
  for v in bank[column]:
    #因為第一欄是索引且各欄位有NaN，所以先判斷是String的才要處理
    if isinstance(v, str):
      v = v.split(".")[-1] #只保留最後一部分的字
      malware_total_permission.append(v)
    else:
      v = "non"
    #print(v)
    l.append(v)
  bank[column] = l
    #print(type(v))

bank_arr = np.array(bank)
unique, counts = np.unique(bank_arr, return_counts=True)
bank_permissionNum = pd.DataFrame(counts, index=unique, columns=["permission"])
bank_permissionNum.drop(['non'],inplace=True)
bank_permissionNum

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

plt.figure(figsize=(15,40))
x = [index for index in bank_permissionNum.index]
y = [int(value) for value in bank_permissionNum.values]
plt.barh(x,y)

permission, counts = np.unique(malware_total_permission, return_counts=True)
malware_permission_num = pd.DataFrame({"permission":permission,"counts":counts})
malware_permission_num

#惡意程式統計出排名前50的permission
malware_50permission = malware_permission_num.sort_values(['counts'], ascending=False).head(50)
malware_50permission

#benign
b1 = pd.read_csv("benign1_permission.csv")
b2 = pd.read_csv("benign2_permission.csv")
b3 = pd.read_csv("benign3_permission.csv")
b4 = pd.read_csv("benign4_permission.csv")
b5 = pd.read_csv("benign5_permission.csv")
b6 = pd.read_csv("benign6_permission.csv")
b7 = pd.read_csv("benign7_permission.csv")
b8 = pd.read_csv("benign8_permission.csv")
b9 = pd.read_csv("benign9_permission.csv")
b10 = pd.read_csv("benign10_permission.csv")
benign_column_name = []
b1_columnName = [c for c in b1.columns[1:]]
b2_columnName = [c for c in b2.columns[1:]]
b3_columnName = [c for c in b3.columns[1:]]
b4_columnName = [c for c in b4.columns[1:]]
b5_columnName = [c for c in b5.columns[1:]]
b6_columnName = [c for c in b6.columns[1:]]
b7_columnName = [c for c in b7.columns[1:]]
b8_columnName = [c for c in b8.columns[1:]]
b9_columnName = [c for c in b9.columns[1:]]
b10_columnName = [c for c in b10.columns[1:]]
benign_column_name = b1_columnName+b2_columnName+b3_columnName+b4_columnName+b5_columnName+b6_columnName+b7_columnName+b8_columnName+b9_columnName+b10_columnName
benign = pd.concat([b1[b1.columns[1:]],b2[b2.columns[1:]],b3[b3.columns[1:]],b4[b4.columns[1:]],b5[b5.columns[1:]],b6[b6.columns[1:]],b7[b7.columns[1:]],b8[b8.columns[1:]],b9[b9.columns[1:]],b10[b10.columns[1:]]], axis = 1, ignore_index=True)
benign.columns = benign_column_name
benign
#benign_column_name

benign_total_permission = []

#刪除android.permission
import numpy as np

for column in benign.columns:
  l = []
  for v in benign[column]:
    #因為第一欄是索引且各欄位有NaN，所以先判斷是String的才要處理
    if isinstance(v, str):
      v = v.split(".")[-1] #只保留最後一部分的字
      benign_total_permission.append(v)
    else:
      v = "non"
    #print(v)
    l.append(v)
  benign[column] = l
    #print(type(v))

benign_arr = np.array(benign)
unique, counts = np.unique(benign_arr, return_counts=True)
benign_permissionNum = pd.DataFrame(counts, index=unique, columns=["permission"])
benign_permissionNum.drop(['non'],inplace=True)
benign_permissionNum

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

plt.figure(figsize=(15,100))
x = [index for index in benign_permissionNum.index]
y = [int(value) for value in benign_permissionNum.values]
plt.barh(x,y)

permission, counts = np.unique(benign_total_permission, return_counts=True)
benign_permission_num = pd.DataFrame({"permission":permission,"counts":counts})
benign_permission_num

#正常程式統計出排名前50的permission
benign_50permission = benign_permission_num.sort_values(['counts'], ascending=False).head(50)
benign_50permission

#資料集中作為特徵的permission
dt_permission = set(benign_50permission['permission'])
dt_permission.update(malware_50permission['permission'])
print(dt_permission)
print(len(dt_permission))

dataset_list = []
#del list (有錯誤跳出再執行這行!)
df_permission = list(dt_permission)
#加一個label欄位
df_permission.append("Malicious")

#sms dataset
#因為前面存csv檔的時候，欄位0是索引，所以這裡要跳過第0欄，從第一欄開始
for column in sms.columns[1:]:
  l = []
  for p in dt_permission:
    if p in sms[column].values:
      l.append(1)
    else:
      l.append(0)
  #加label
  l.append("true")
  dataset_list.append(l)

#adware dataset
#因為前面存csv檔的時候，欄位0是索引，所以這裡要跳過第0欄，從第一欄開始
for column in adware.columns[1:]:
  l = []
  for p in dt_permission:
    if p in adware[column].values:
      l.append(1)
    else:
      l.append(0)
  #加label
  l.append("true")
  dataset_list.append(l)

#banking dataset
#因為前面存csv檔的時候，欄位0是索引，所以這裡要跳過第0欄，從第一欄開始
for column in bank.columns[1:]:
  l = []
  for p in dt_permission:
    if p in bank[column].values:
      l.append(1)
    else:
      l.append(0)
  #加label
  l.append("true")
  dataset_list.append(l)

#benign dataset
#因為前面存csv檔的時候，欄位0是索引，所以這裡要跳過第0欄，從第一欄開始
for column in benign.columns[1:]:
  l = []
  for p in dt_permission:
    if p in benign[column].values:
      l.append(1)
    else:
      l.append(0)
  #加label
  l.append("false")
  dataset_list.append(l)

dataset = pd.DataFrame(dataset_list, columns=df_permission)
dataset

#把資料集打亂
from sklearn.utils import shuffle
dataset = shuffle(dataset,)
dataset

#儲存資料集成csv檔
dataset.to_csv("apk_dataset.csv",index=False)

import pandas as pd

#讀入csv檔(如果從上面執行下來的話，這裡可做可不做)
dataset = pd.read_csv("apk_dataset.csv")

#看資料集惡意apk和正常apk的數量
dataset["Malicious"].value_counts()

#把target label轉成0,1形式
dataset['Malicious'] = dataset['Malicious'].astype('category').cat.codes
dataset.head(10)

#資料集切割(train:80%, test:20%)
from sklearn.model_selection import train_test_split
X = dataset.drop(["Malicious"],axis = 1)
y= dataset['Malicious']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# SVM模型


*   poly
*   rbf




"""

from sklearn.svm import SVC

#poly
svm_poly = SVC(kernel='poly',class_weight='balanced')
svm_poly.fit(X_train,y_train)
print("訓練集的準確率:{}".format(svm_poly.score(X_train,y_train)))
print("測試集的準確率:{}".format(svm_poly.score(X_test,y_test)))

from sklearn import metrics
pred = svm_poly.predict(X_test)
print(metrics.classification_report(y_test,pred))

#rbf
svm_rbf = SVC(kernel='rbf',class_weight='balanced')
svm_rbf.fit(X_train,y_train)
print("訓練集的準確率:{}".format(svm_rbf.score(X_train,y_train)))
print("測試集的準確率:{}".format(svm_rbf.score(X_test,y_test)))

from sklearn import metrics
pred = svm_rbf.predict(X_test)
print(metrics.classification_report(y_test,pred))

"""# RandomForest模型"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=1000, random_state=100, class_weight='balanced')
rf.fit(X_train,y_train)
print("訓練集的準確率:{}".format(rf.score(X_train,y_train)))
print("測試集的準確率:{}".format(rf.score(X_test,y_test)))

from sklearn import metrics
pred = rf.predict(X_test)
print(metrics.classification_report(y_test,pred))

"""# CNN模型

第一部分：前處理
"""

import pandas as pd

dataset = pd.read_csv("apk_dataset.csv")
dataset.head(10)

import numpy as np
from PIL import Image
#把特徵變成圖片形式(8*9)
feature_len = len(dataset.columns)-1 #全部特徵長度(不包括target label)
w = 9 #寬=9

apk_dt = np.array(dataset.drop(['Malicious'],axis=1))
image_list = []

for row in range(0,len(dataset)):
  l = []
  for i in range(0,feature_len,w):
    l.append(list(apk_dt[row,i:i+w]))
  
  l[-1]=l[-1]+[0]*(w-len(l[-1]))
  img=Image.fromarray(np.array(l,dtype='int8'),"L") #轉成灰階圖片(因為跑模型用0,1做比較快，所以這裡直接用0,1轉成圖片形式)
  image_list.append(img)

#看一張確認一下
import matplotlib.pyplot as plt

plt.imshow(image_list[0],cmap='gray')

#刪除image的最後一個axis
#def squeez_tensor(img):
#  img = tf.squeeze(img)
#  return img

import tensorflow as tf
from tensorflow import keras

label = dataset['Malicious'] #target label
#將label轉成one-hot code
onehot_label = keras.utils.to_categorical(label)

#把PIL image轉成numpy array，再將每個numpy array轉成list
img_array = [list(tf.keras.preprocessing.image.img_to_array(img)) for img in image_list]
#轉成tensor
img_ds = tf.data.Dataset.from_tensor_slices(img_array)

label_ds = tf.data.Dataset.from_tensor_slices(onehot_label)


# 合併圖片與label資料集
full_ds = tf.data.Dataset.zip((img_ds,label_ds))
# 打散
shuffle_buffer = 20
full_ds = full_ds.shuffle(shuffle_buffer,reshuffle_each_iteration=False)

# 取出Tensor圖片來看看
plt.figure(figsize=(12, 8))
for index,(img,label) in enumerate(full_ds.take(6)):
    #l = np.argmax(label.numpy())
    plt.subplot(2,3,index+1)
    plt.imshow(tf.squeeze(img),cmap='gray')
    
    plt.axis("off")

# 切割成training data與validation data和testing data
#train & test data
total_len = len(dataset) 
train_len = int(0.8*total_len)
test_len = total_len - train_len
train_ds = full_ds.take(train_len)
test_ds = full_ds.take(test_len)
#train & validation dat
train_total_len = train_len
train_len = int(0.8*train_len)
val_len = train_total_len - train_len
val_ds = train_ds.skip(train_len)
train_ds = train_ds.take(train_len)


print("train size : ",train_len," val size : ",val_len)

# 添加batch
batch_size = 100

train_ds = train_ds.batch(batch_size)
val_ds = val_ds.batch(batch_size)

# 查看添加batch後的維度
trainiter = iter(train_ds)
x,y = trainiter.next()
print("training image batch shape : ",x.shape)
print("training label batch shape : ",y.shape)

# 查看添加batch後的維度
trainiter = iter(val_ds)
x,y = trainiter.next()
print("training image batch shape : ",x.shape)
print("training label batch shape : ",y.shape)

# 查看添加batch後的維度
trainiter = iter(test_ds)
x,y = trainiter.next()
print("training image batch shape : ",x.shape)
print("training label batch shape : ",y.shape)

"""第二部分：建立模型"""

from tensorflow import keras
from tensorflow.keras import layers

input_shape = (8,9,1)
num_classes = 2 #label種類有幾個


model = keras.Sequential(
    [
    keras.Input(shape=input_shape),
    layers.Conv2D(32, kernel_size = (3,3), activation = "relu", padding = "same"),
    layers.Conv2D(64, kernel_size = (3,3), activation = "relu"),
    layers.MaxPooling2D(pool_size = (2,2)),
    
    layers.Dropout(0.5),
    
    layers.Flatten(),
    
    
    layers.Dense(512, activation = "relu"),
    
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation = "softmax"),
    ]
)

model.summary()

"""第三部分：制定訓練計畫"""

epochs = 100


model.compile(loss = "categorical_crossentropy", optimizer = "adam", metrics = ["accuracy"])
#設置earlt stopping
earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=15, mode = 'max')

history = model.fit(train_ds,epochs=epochs,validation_data=val_ds,callbacks=[earlystop_callback])

"""第三部分：評估模型

"""

print(history.history.keys())

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

# 讀入測試資料並評估模型

#test dataset添加batch
test_ds = test_ds.batch(batch_size)
score = model.evaluate(test_ds)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

from sklearn.metrics import confusion_matrix
test_ds = test_ds.unbatch()
#trainiter = iter(test_ds)
#test_x,test_y = trainiter.next()
test_x_ds = test_ds.map(lambda *x: x[0])
test_y_ds = test_ds.map(lambda *x: x[1])
#test_x_ds = tf.data.Dataset.from_tensor_slices(test_x)
test_x_ds = test_x_ds.batch(batch_size)
y_pred = model.predict(test_x_ds)
y_pred = np.argmax(y_pred,axis=1)
#confusion_matrix(test_y,y_pred)
y_pred





"""# CNN模型2"""

from tensorflow import keras
from tensorflow.keras import layers

input_shape = (8,9,1)
num_classes = 2 #label種類有幾個


model2 = keras.Sequential(
    [
    keras.Input(shape=input_shape),
    layers.Conv2D(32, kernel_size = (3,3), activation = "relu", padding = "same"),
    layers.Conv2D(64, kernel_size = (3,3), activation = "relu"),
    layers.MaxPooling2D(pool_size = (2,2)),
    
    layers.Dropout(0.5),
    
    layers.Flatten(),
    
    
    layers.Dense(512, activation = "relu"),
    layers.Dense(256, activation = "relu"),
    layers.Dense(128, activation = "relu"),
    layers.Dense(64, activation = "relu"),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation = "softmax"),
    ]
)

model2.summary()

epochs = 100


model2.compile(loss = "categorical_crossentropy", optimizer = "adam", metrics = ["accuracy"])
#設置earlt stopping
earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=15, mode = 'max')

history2 = model2.fit(train_ds,epochs=epochs,validation_data=val_ds,callbacks=[earlystop_callback])

print(history2.history.keys())

plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

# 讀入測試資料並評估模型
test_ds = test_ds.batch(batch_size)
score = model2.evaluate(test_ds)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

"""# CNN模型3"""

from tensorflow import keras
from tensorflow.keras import layers

input_shape = (8,9,1)
num_classes = 2 #label種類有幾個


model3 = keras.Sequential(
    [
    keras.Input(shape=input_shape),
    layers.Conv2D(32, kernel_size = (3,3), activation = "relu", padding = "same"),
    layers.Conv2D(64, kernel_size = (3,3), activation = "relu"),
    layers.Conv2D(128, kernel_size = (3,3), activation = "relu", padding = "same"),
    layers.MaxPooling2D(pool_size = (2,2)),
    
    layers.Dropout(0.5),
    
    layers.Flatten(),
    
    
    layers.Dense(512, activation = "relu"),
    layers.Dense(256, activation = "relu"),
    layers.Dense(128, activation = "relu"),
    layers.Dense(64, activation = "relu"),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation = "softmax"),
    ]
)

model3.summary()

epochs = 100


model3.compile(loss = "categorical_crossentropy", optimizer = "adam", metrics = ["accuracy"])
#設置earlt stopping
earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=15, mode = 'max')

history3 = model3.fit(train_ds,epochs=epochs,validation_data=val_ds,callbacks=[earlystop_callback])

print(history3.history.keys())

plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

# 讀入測試資料並評估模型
test_ds = test_ds.unbatch()
test_ds = test_ds.batch(batch_size)
score = model3.evaluate(test_ds)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

"""# CNN模型4"""

from tensorflow import keras
from tensorflow.keras import layers

input_shape = (8,9,1)
num_classes = 2 #label種類有幾個


model4 = keras.Sequential(
    [
    keras.Input(shape=input_shape),
    layers.Conv2D(32, kernel_size = (3,3), activation = "relu", padding = "same"),
    layers.Conv2D(64, kernel_size = (3,3), activation = "relu"),
    layers.Conv2D(64, kernel_size = (3,3), activation = "relu", padding = "same"),
    layers.MaxPooling2D(pool_size = (2,2)),
    
    layers.Dropout(0.5),
    
    layers.Flatten(),
    
    
    layers.Dense(512, activation = "relu"),
    layers.Dense(256, activation = "relu"),
    layers.Dense(128, activation = "relu"),
    layers.Dense(64, activation = "relu"),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation = "softmax"),
    ]
)

model4.summary()

epochs = 100


model4.compile(loss = "categorical_crossentropy", optimizer = "adam", metrics = ["accuracy"])
#設置earlt stopping
earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=15, mode = 'max')

history4 = model4.fit(train_ds,epochs=epochs,validation_data=val_ds,callbacks=[earlystop_callback])

print(history4.history.keys())

plt.plot(history4.history['accuracy'])
plt.plot(history4.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

# 讀入測試資料並評估模型
test_ds = test_ds.unbatch()
test_ds = test_ds.batch(batch_size)
score = model4.evaluate(test_ds)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

"""# 【加分題】使用現有 CNN 架構訓練
使用Vgg16 model
"""

import numpy as np
from PIL import Image
#把特徵變成圖片形式(32*32)
feature_len = len(dataset.columns)-1 #全部特徵長度(不包括target label)
w = 32 #寬=32
h = 32 #長=32

apk_dt = np.array(dataset.drop(['Malicious'],axis=1))
image_list = []

for row in range(0,len(dataset)):
  l = []
  for i in range(0,feature_len,w):
    l.append(list(apk_dt[row,i:i+w]))
  
  l[-1]=l[-1]+[0]*(w-len(l[-1]))
  while(len(l)<h):
    l.append([0]*w)
  #print(len(l))
  img=Image.fromarray(np.array(l,dtype='int8'),"L") #轉成灰階圖片
  image_list.append(img)

import tensorflow as tf
from tensorflow import keras

label = dataset['Malicious'] #target label
#將label轉成one-hot code
onehot_label = keras.utils.to_categorical(label)

#把PIL image轉成numpy array，再將每個numpy array轉成list
img_array = [list(tf.keras.preprocessing.image.img_to_array(img)) for img in image_list]
#轉成tensor
img_ds = tf.data.Dataset.from_tensor_slices(img_array)

label_ds = tf.data.Dataset.from_tensor_slices(onehot_label)


# 合併圖片與label資料集
full_ds = tf.data.Dataset.zip((img_ds,label_ds))
# 打散
shuffle_buffer = 20
full_ds = full_ds.shuffle(shuffle_buffer,reshuffle_each_iteration=False)

import matplotlib.pyplot as plt

# 取出Tensor圖片來看看
plt.figure(figsize=(12, 8))
for index,(img,label) in enumerate(full_ds.take(6)):
    #l = np.argmax(label.numpy())
    plt.subplot(2,3,index+1)
    plt.imshow(tf.squeeze(img),cmap='gray')
    
    plt.axis("off")

from keras.applications.vgg16 import preprocess_input, decode_predictions
import numpy as np
import tensorflow as tf


grayscale_batch = np.squeeze(np.array(img_array))

print(grayscale_batch.shape)  # (100, 32, 32)
rgb_batch = np.repeat(grayscale_batch[..., np.newaxis], 3, -1)
print(rgb_batch.shape)  # (12852, 32, 32, 3)

from keras.applications.vgg16 import VGG16
from keras.layers import Input, Flatten, Dense
from keras.models import Model
vgg_model = VGG16(include_top=False,input_shape= (32,32,3))

print(vgg_model.summary())

#cnn的部分用vgg_model
output_vgg = vgg_model(vgg_model.input)
#加full-connected layers 
x = Flatten(name='flatten')(output_vgg)
x = Dense(4096, activation='relu', name='fc1')(x)
x = Dense(4096, activation='relu', name='fc2')(x)
x = Dense(2, activation='softmax', name='predictions')(x)

#建自己的keras model 
myvgg_model = Model(vgg_model.input, x)
print(myvgg_model.summary())

myvgg_model.compile(loss = "categorical_crossentropy", optimizer = "adam", metrics = ["accuracy"])

score = myvgg_model.evaluate(rgb_batch,onehot_label)
print("Test loss:", score[0])
print("Test accuracy:", score[1])